\documentclass[a4paper]{article}

%% Sets page size and margins
\usepackage{fullpage}
\usepackage{geometry}

\usepackage[table]{xcolor} % Must come before packages that load xcolor

\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{array}
\usepackage{booktabs}
\usepackage{color}
\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{mdwlist}
\usepackage{multicol}
\usepackage[all]{xy}
\usepackage{extarrows}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}

\usepackage[normalem]{ulem}
\setlength{\parskip}{1ex}

\begin{document}

\title{Introduction to Retrograde Analysis}
\author{Christopher Sumnicht}
\maketitle

\section{Definitions}

Gamescrafters is a group dedicated to \textbf{strongly solving two-player abstract strategy games}. Roughly speaking, we play board games perfectly.

An \textbf{abstract strategy game} is a completely deterministic game with no hidden information such as fog. Examples of such games include "Tic-Tac-Toe", "Chess", "Othello", and "Go". Some non-examples are "Poker" (cards are dealt at random, and you can't see the other players' hands), "Blackjack", and "Trouble". 

It can be shown, in an abstract strategy game, every position is either a \textit{losing position}, \textit{wining position}, \textit{tied position}, or a \textit{drawn position} and we refer to this as the \textbf{value of a position} \footnote{For now, we will omit discussion about tied and drawn positions for the sake of simplicity}. Observe that if a position is a losing position for player one, it is a winning position for player two. A game is \textbf{strongly solved} when we know the "value" of every position.

Before we continue with more definitions let's analyze a game and look at how all of these definitions play out.

\section{ 4 - 0 }

\begin{quote}
    \textbf{Warning} This game is going to be pretty dumb. The main reason for using it instead of a more exciting example is that it is small enough to view every possible position.
\end{quote}

The game 4 - 0 works as follows: There are four items placed on a table and two players. Each player can either take $1$ or $2$ items from the table. The first person that can't take any items loses.

For example, a game could go as follows:

\begin{enumerate}
    \item{Player one takes $1$ item. $3$ items are left}
    \item{Player two takes $1$ item. $2$ items are left}
    \item{Player one takes $2$ items. $0$ items are left}
    \item{Player two has no availble moves and loses.}
\end{enumerate}

\section{Retrograde Analysis}

\begin{quote}
    Can either player one or player two guarantee a win regardless of the other player's strategy?
\end{quote}

To answer this question, let's work with an even dumber game. Instead of starting out with $4$ items, let's start at $0$ instead. Let's look at an example game:

\begin{enumerate}
    \item{Player one loses.}
\end{enumerate}

Wow, that was unexpected. It looks like this has to always be a win for player two. We have made some progress, we finally have \textbf{strongly solved} a game. We know the value of every (and by every, I also mean the only) position in this game and it is a loss for player one.

Let's keep working and consider 1 - 0 and see how the game plays out:

\begin{enumerate}
    \item{Player one must take $1$ item away.}
    \item{Player two has no moves and loses.}
\end{enumerate}

We are on fire. We have just strongly solved 1 - 0. Let's look at 2 - 0. 2 - 0 is interesting because player one now has a choice. Should he take away 2? Or should he take away 1? Well let's look at how the two differnt strategies can play out:

\begin{enumerate}
    \item{Player one takes $2$ items away.}
    \item{Player two has no moves and loses.}
\end{enumerate}

Nice. That worked out pretty well.

\begin{enumerate}
    \item{Player one takes $1$ item away.}
    \item{Player two must take $1$ item away.}
    \item{Player one has no moves and loses.}
\end{enumerate}

Ouch. Not so good. It's important to note, that these $2$ games are the only games possible in 2 - 0. We can represent all of 2 - 0 as a tree. The nodes are the positions and the arrows are the moves. (See Figure 1 TODO). In Figure 2 we labeled each of the positions values (from player one's perspective).

An \textbf{immediate child of a position} $p$ is a new position generated by performing a move on $p$. $1$ and $0$ are (and are the only) immediate children of $2$ in this example.

We can observe the following fact:

\begin{quote}
    Assume a player has arrived at position $p$ and we have the values of each immediate child. We can conclude the following:
    \begin{enumerate}
        \item{ If there is an immediate child with the value of "win", the player can move to that position, and always win.}
        \item{ If every immediate child has a value of "loss", the player can only move to losing positions. As a result, the other player can always force a win.}
    \end{enumerate}
\end{quote}

Hence, for 2 - 0, player one can always force a win as player one can always choose to take $2$ items away and force a win.

From this we can draw the tree for 3 - 0 and build up solutions to the tree from the bottom up.

\begin{quote}
    \textbf{Exercise} Construct the tree for 3 - 0 and 4 - 0. Which ones can player one always win? Which ones can player two always win?

    \textbf{Exercise} Consider a more general game $n$ - 0. For what values of $n$ can player one always win? Which one can player two always win?
\end{quote}

\section{ Strongly vs Weakly Solving a Game }

There are three major classifications of solving: \textbf{ultra-weak}, \textbf{weak} and \textbf{strong}. To keep things simple, we are not going to emphasize the difference between ultra-weak and weak. Instead, we will emphasize the difference between weak and strong.

Notice that in order to show that a position is a winning positiion we need to only find \textbf{one} immediate child with a win value. We \textit{could} stop searching after we find one immediate child with a win if all we wish to do is determine which player will win. Let's call this algorithm \textbf{quick-stop}. If all we want to do is prove a game is a win or loss for player one, quick-stop can cut down the amount of time needed to search.

Suppose, however, we want to make a computer player that is no fun to play and always beats everyone (and to clarify, we \textit{do} want to make a computer player that is no fun to play and always beats everyone). We perform quick-stop, store the values in a database, and ask the computer to use these values to play against a human. Say the human is player one, and player one in theory can always force a win. Player one makes a losing move because player one doesn't know any better. quick-stop doesn't guarantee the computer may have no knowledge of this losing move. Even though there certainly exists a method of disgracing player one, the computer may have no idea what to do. Hence, we must make sure to determine that value for every position in order to make a functional computer player.

\section{ Calculating Remoteness }

There is another problem: Say we have strongly solved a game and know the value for every possible game position. Suppose that there are two immediate children that the computer can move to and force a win. How do we decide which one to follow?

\begin{quote}
    Win as fast as possible and lose as slow as possible.
\end{quote}

Let's clarify what is meant by "fastest" and "slowest". The definition is, once again, inductive. When the game is trivially over, assign the remoteness of that position to $0$. Now suppose we are at some point in time where the player can make a move to a collection of winning positions. Suppose that each immediate child already has the remoteness calculated. As we can move to a winning position, we want to minimize the remoteness. We find the smallest remoteness amongst the children and add one to it to calculate the remoteness of the current position.

\begin{quote}
    \textbf{Exercise} What happens if the player can only move to losing positions? How does this change how remoteness is calculated?
\end{quote}

\end{document}
